{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c755bf4",
   "metadata": {},
   "source": [
    "<h1 style='background-color: Purple; padding: 10px; color: white'> ON THE MARKET </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b5244",
   "metadata": {},
   "source": [
    "<h1 style='background-color: Purple; padding: 10px; color: white'> Sales </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d870e",
   "metadata": {},
   "source": [
    "First things first, we will import the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e418af4",
   "metadata": {},
   "source": [
    "Note: You have scrapped for Agents yet\n",
    "        The next button is not working yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0610b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8278900",
   "metadata": {},
   "source": [
    "Next, we will load in the dataset containing the list of postcode for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91de3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('London postcode districts.xlsx - PC DIST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a39821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OnTheMarket_sales(i, Trans_type, website, df):\n",
    "    s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "    #s = Service(\"C:\\\\Users\\\\akint\\\\Downloads\\\\Set up files\\\\chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service= s)\n",
    "\n",
    "    driver.get('https://www.onthemarket.com/') \n",
    "\n",
    "    driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div/div/div[2]/button').click()\n",
    "    time.sleep(2)\n",
    "    driver.maximize_window()\n",
    "\n",
    "\n",
    "    time.sleep(1.2)\n",
    "    search = driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div/div/div/div[2]/div/div[1]/div/div/input')\n",
    "    search.send_keys(postcode)\n",
    "\n",
    "    time.sleep(10)\n",
    "    driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div/div/div/div[2]/div/div[1]/div/div/button').click()\n",
    "    #driver.find_element(by = 'class name', value = 'otm-Button').click()\n",
    "    \n",
    "    # Enable list view\n",
    "    time.sleep(10)\n",
    "    driver.find_element(By.XPATH, '/html/body/div[6]/div[3]/div[3]/div/div/div[2]/div/div[3]/div[1]/span[2]/a/span').click()\n",
    "    \n",
    "    Trans_type = []\n",
    "    address = []\n",
    "    types = []\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    prices = []\n",
    "    desc = []\n",
    "    date_added = []\n",
    "    agent_list = []\n",
    "    property_url = []\n",
    "    website = []\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    j = 1\n",
    "    \n",
    "    time.sleep(2)\n",
    "    print(\"{} {} {} {}\".format('scraping page', j,'from', postcode ))\n",
    "    address_list = driver.find_elements(By.XPATH, '//div[2]/p/span[2]/a')\n",
    "    type_list = driver.find_elements(By.XPATH, \"//div[2]/p/span[1]/a\")\n",
    "    bedroom_list = driver.find_elements(By.XPATH, '//div[2]/div[4]/div[1]')\n",
    "    bathroom_list = driver.find_elements(By.XPATH, '//div[2]/div[4]/div[2]')\n",
    "    price_list = driver.find_elements(By.XPATH, '//div[2]/div[2]/a[2]')\n",
    "    desc_list = driver.find_elements(By.XPATH, '//div[2]/p/span[2]/a')\n",
    "    date_added_list = driver.find_elements(By.XPATH, '//div[3]/div[1]/div[2]/a')\n",
    "    agent_list_list = driver.find_elements(By.XPATH, '//div[3]/div[1]/div[2]/small/a')\n",
    "    property_url_list = driver.current_url\n",
    "    Trans_type_list = Trans_type\n",
    "    website_list = website\n",
    "    for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "        time.sleep(1.0)\n",
    "        address.append(address_item.text)\n",
    "        types.append(type_item.text)\n",
    "        bedrooms.append(bedroom_item.text)\n",
    "        bathrooms.append(bathroom_item.text)\n",
    "        prices.append(price_item.text)\n",
    "        desc.append(address_item.text + '. ' + type_item.text)\n",
    "        date_added.append(date_added_item.text)\n",
    "        agent_list.append(agent_list_item.text)\n",
    "        property_url.append(property_url_list)\n",
    "        Trans_type.append(Trans_type_list)\n",
    "        website.append(website_list)\n",
    "\n",
    "      \n",
    "    time.sleep(1.3)\n",
    "    # get the height of the page\n",
    "    page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "    # scroll to the middle of the page using JavaScript\n",
    "    driver.execute_script(f\"window.scrollTo(0, {page_height//3});\")\n",
    "\n",
    "    time.sleep(1.5)\n",
    "    driver.find_element(By.XPATH, '//div[5]/div/div/button').click()\n",
    "    time.sleep(1.1) \n",
    "    next_botton = driver.find_element(By.XPATH, '//div/a/button') \n",
    "    \n",
    "    \n",
    "    last_botton_check = driver.find_element(By.XPATH, '//div/button') \n",
    "    html = last_botton_check.get_attribute('outerHTML') \n",
    "    if 'disabled' in html:\n",
    "        print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "    \n",
    "    time.sleep(1.3)\n",
    "    next_botton.click()\n",
    "    \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Sales','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'OnTheMartket', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}S{i+1:05d}' for i in range(len(df1))])\n",
    "    #print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "    \n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    i=2\n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        print(\"{} {} {} {}\".format('scraping page', i,'from', postcode ))\n",
    "        address_list = driver.find_elements(By.XPATH, '//div[2]/p/span[2]/a')\n",
    "        type_list = driver.find_elements(By.XPATH, \"//div[2]/p/span[1]/a\")\n",
    "        bedroom_list = driver.find_elements(By.XPATH, '//div[2]/div[4]/div[1]')\n",
    "        bathroom_list = driver.find_elements(By.XPATH, '//div[2]/div[4]/div[2]')\n",
    "        price_list = driver.find_elements(By.XPATH, '//div[2]/div[2]/a[2]')\n",
    "        desc_list = driver.find_elements(By.XPATH, '//div[2]/p/span[2]/a')\n",
    "        date_added_list = driver.find_elements(By.XPATH, '//div[3]/div[1]/div[2]/a')\n",
    "        agent_list_list = driver.find_elements(By.XPATH, '//div[3]/div[1]/div[2]/small/a')\n",
    "        property_url_list = driver.current_url\n",
    "        Trans_type_list = Trans_type\n",
    "        website_list = website\n",
    "        for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "            time.sleep(1.0)\n",
    "            address.append(address_item.text)\n",
    "            types.append(type_item.text)\n",
    "            bedrooms.append(bedroom_item.text)\n",
    "            bathrooms.append(bathroom_item.text)\n",
    "            prices.append(price_item.text)\n",
    "            desc.append(address_item.text + '. ' + type_item.text)\n",
    "            date_added.append(date_added_item.text)\n",
    "            agent_list.append(agent_list_item.text)\n",
    "            property_url.append(property_url_list)\n",
    "            Trans_type.append(Trans_type_list)\n",
    "            website.append(website_list)\n",
    "\n",
    "        \n",
    "        time.sleep(2.5)\n",
    "        # get the height of the page\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "        # scroll to the middle of the page using JavaScript\n",
    "        driver.execute_script(f\"window.scrollTo(0, {page_height//3});\")\n",
    "        \n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            time.sleep(3.5)\n",
    "            driver.find_element(By.XPATH, '/html/body/div[6]/div[3]/div[3]/div/div/div[4]/div/div[2]/div/a[2]/button')\n",
    "            next_botton = driver.find_element(By.XPATH, '/html/body/div[6]/div[3]/div[3]/div/div/div[4]/div/div[2]/div/a[2]/button')\n",
    "            next_botton.click()\n",
    "            i += 1\n",
    "        except:\n",
    "            print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "            break\n",
    "            \n",
    "        time.sleep(1.3) \n",
    "        \n",
    "         \n",
    "        \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Sales','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'OnTheMartket', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}S{i+1:05d}' for i in range(len(df1))])\n",
    "    print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "\n",
    "    \n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2233b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1 from BR1\n",
      "scraping page 2 from BR1\n",
      "------------------------------- SCRAPING COMPLETED FOR BR1\n",
      "Total numbers of properties available in BR1 is 26\n",
      "scraping page 1 from BR2\n",
      "scraping page 2 from BR2\n",
      "scraping page 3 from BR2\n",
      "scraping page 4 from BR2\n",
      "scraping page 5 from BR2\n",
      "scraping page 6 from BR2\n",
      "scraping page 7 from BR2\n",
      "scraping page 8 from BR2\n",
      "scraping page 9 from BR2\n",
      "scraping page 10 from BR2\n",
      "scraping page 11 from BR2\n",
      "scraping page 12 from BR2\n",
      "scraping page 13 from BR2\n",
      "scraping page 14 from BR2\n",
      "scraping page 15 from BR2\n",
      "scraping page 16 from BR2\n",
      "scraping page 17 from BR2\n",
      "scraping page 18 from BR2\n",
      "------------------------------- SCRAPING COMPLETED FOR BR2\n",
      "Total numbers of properties available in BR2 is 212\n",
      "scraping page 1 from BR3\n",
      "scraping page 2 from BR3\n",
      "------------------------------- SCRAPING COMPLETED FOR BR3\n",
      "Total numbers of properties available in BR3 is 18\n",
      "scraping page 1 from BR4\n",
      "scraping page 2 from BR4\n",
      "------------------------------- SCRAPING COMPLETED FOR BR4\n",
      "Total numbers of properties available in BR4 is 24\n",
      "scraping page 1 from BR5\n",
      "scraping page 2 from BR5\n",
      "------------------------------- SCRAPING COMPLETED FOR BR5\n",
      "Total numbers of properties available in BR5 is 28\n",
      "scraping page 1 from BR6\n",
      "scraping page 2 from BR6\n",
      "------------------------------- SCRAPING COMPLETED FOR BR6\n",
      "Total numbers of properties available in BR6 is 24\n",
      "scraping page 1 from BR7\n",
      "scraping page 2 from BR7\n",
      "scraping page 3 from BR7\n",
      "scraping page 4 from BR7\n",
      "------------------------------- SCRAPING COMPLETED FOR BR7\n",
      "Total numbers of properties available in BR7 is 50\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[6]/div[3]/div[3]/div/div/div[2]/div/div[3]/div[1]/span[2]/a/span\"}\n  (Session info: chrome=112.0.5615.140)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00EFDCE3+50899]\n\t(No symbol) [0x00E8E111]\n\t(No symbol) [0x00D95588]\n\t(No symbol) [0x00DC08F9]\n\t(No symbol) [0x00DC0AFB]\n\t(No symbol) [0x00DEF902]\n\t(No symbol) [0x00DDB944]\n\t(No symbol) [0x00DEE01C]\n\t(No symbol) [0x00DDB6F6]\n\t(No symbol) [0x00DB7708]\n\t(No symbol) [0x00DB886D]\n\tGetHandleVerifier [0x01163EAE+2566302]\n\tGetHandleVerifier [0x011992B1+2784417]\n\tGetHandleVerifier [0x0119327C+2759788]\n\tGetHandleVerifier [0x00F95740+672048]\n\t(No symbol) [0x00E98872]\n\t(No symbol) [0x00E941C8]\n\t(No symbol) [0x00E942AB]\n\t(No symbol) [0x00E871B7]\n\tBaseThreadInitThunk [0x758E0099+25]\n\tRtlGetAppContainerNamedObjectPath [0x77757B6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77757B3E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loop through postcodes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m postcode \u001b[38;5;129;01min\u001b[39;00m codes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostcode district\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# call the function and pass the empty DataFrame as an argument\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m \u001b[43mOnTheMarket_sales\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpostcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOnTheMarket\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# append the df1 DataFrame to the empty DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df1], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mOnTheMarket_sales\u001b[1;34m(i, Trans_type, website, df)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#driver.find_element(by = 'class name', value = 'otm-Button').click()\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Enable list view\u001b[39;00m\n\u001b[0;32m     22\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/html/body/div[6]/div[3]/div[3]/div/div/div[2]/div/div[3]/div[1]/span[2]/a/span\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     25\u001b[0m Trans_type \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m address \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:831\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    828\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    829\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[6]/div[3]/div[3]/div/div/div[2]/div/div[3]/div[1]/span[2]/a/span\"}\n  (Session info: chrome=112.0.5615.140)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00EFDCE3+50899]\n\t(No symbol) [0x00E8E111]\n\t(No symbol) [0x00D95588]\n\t(No symbol) [0x00DC08F9]\n\t(No symbol) [0x00DC0AFB]\n\t(No symbol) [0x00DEF902]\n\t(No symbol) [0x00DDB944]\n\t(No symbol) [0x00DEE01C]\n\t(No symbol) [0x00DDB6F6]\n\t(No symbol) [0x00DB7708]\n\t(No symbol) [0x00DB886D]\n\tGetHandleVerifier [0x01163EAE+2566302]\n\tGetHandleVerifier [0x011992B1+2784417]\n\tGetHandleVerifier [0x0119327C+2759788]\n\tGetHandleVerifier [0x00F95740+672048]\n\t(No symbol) [0x00E98872]\n\t(No symbol) [0x00E941C8]\n\t(No symbol) [0x00E942AB]\n\t(No symbol) [0x00E871B7]\n\tBaseThreadInitThunk [0x758E0099+25]\n\tRtlGetAppContainerNamedObjectPath [0x77757B6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77757B3E+238]\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = OnTheMarket_sales(postcode, 'Sales', 'OnTheMarket', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5911bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('onTheMarket_sales_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0812f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kinleigh Folkard & Hayward - Bromley Sales', 'Sinclair Hammelton - Bromley Sales', 'Sinclair Hammelton - Bromley Sales', 'Foxtons - Bromley', 'Choices - Daniels Property Services', '1st Choice Estates - Camberwell', \"Neo's Estate Agents - Hayes Bromley\", 'Homezone Property Services - Bromley', 'APX Properties - Bromley', 'Foxtons - Bromley', 'Choices - Daniels Property Services', \"Truepenny's Property Consultants - Charlton\", 'Edward Ashdale - Bromley', 'Homezone Property Services - Beckenham', 'BR Estate Agent - Bromley', 'Home Castle Estate Agents - South Norwood', 'Kinleigh Folkard & Hayward - Bromley Sales', 'Kinleigh Folkard & Hayward - Bromley Sales', 'Kinleigh Folkard & Hayward - Bromley Sales', 'Browne Estate Agents - Bromley', 'Coady Phillips Estate Agents - Bromley', 'Sinclair Hammelton - Bromley Sales', 'Sinclair Hammelton - Bromley Sales']\n"
     ]
    }
   ],
   "source": [
    "s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "#s = Service(\"C:\\\\Users\\\\akint\\\\Downloads\\\\Set up files\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service= s)\n",
    "\n",
    "driver.get('https://www.onthemarket.com/') \n",
    "\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div/div/div[2]/button').click()\n",
    "time.sleep(2)\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "time.sleep(1.2)\n",
    "search = driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div/div/div/div[2]/div/div[1]/div/div/input')\n",
    "search.send_keys('BR1')\n",
    "\n",
    "time.sleep(10)\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[3]/div/div/div/div/div[2]/div/div[1]/div/div/button').click()\n",
    "\n",
    "time.sleep(10)\n",
    "driver.find_element(By.XPATH, '/html/body/div[6]/div[3]/div[3]/div/div/div[2]/div/div[3]/div[1]/span[2]/a/span').click()\n",
    "\n",
    "agent= []\n",
    "time.sleep(1.2)\n",
    "element = driver.find_elements(By.XPATH, '//div[3]/div[1]/div[2]/small/a') \n",
    "for i in element:\n",
    "    time.sleep(1.7)\n",
    "    agent.append(i.text)\n",
    "print(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f09a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
